name: Google Shopping Scraper with Audio Captcha

on:
  workflow_dispatch:
    inputs:
      input_filename:
        description: "Input CSV filename on FTP"
        required: true
        default: "google_shopping.csv"
        type: string
      total_chunks:
        description: "Number of chunks to split into"
        required: true
        default: "4"
        type: string

jobs:
  plan:
    runs-on: ubuntu-latest
    outputs:
      matrix: ${{ steps.matrix.outputs.matrix }}
    steps:
      - id: matrix
        run: |
          TOTAL_CHUNKS=${{ github.event.inputs.total_chunks || 4 }}

          MATRIX="["
          for ((i=1;i<=TOTAL_CHUNKS;i++)); do
            MATRIX+="{\"chunk_id\":$i},"
          done
          MATRIX="${MATRIX%,}]"

          echo "matrix=$MATRIX" >> "$GITHUB_OUTPUT"
          echo "Matrix: $MATRIX"

  scrape:
    needs: plan
    runs-on: ubuntu-22.04
    timeout-minutes: 120  # Increased timeout for captcha solving

    strategy:
      fail-fast: false
      matrix:
        include: ${{ fromJson(needs.plan.outputs.matrix) }}

    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install system dependencies with audio support
        run: |
          sudo apt-get update
          sudo apt-get install -y \
            wget \
            gnupg \
            google-chrome-stable \
            xvfb \
            pulseaudio \
            ffmpeg \
            libasound2 \
            libasound2-dev \
            libatk-bridge2.0-0 \
            libgtk-3-0 \
            libnss3 \
            libxss1 \
            libgbm1 \
            libu2f-udev \
            fonts-liberation \
            libpulse-dev \
            portaudio19-dev \
            libjack-dev \
            lftp

          # Setup virtual audio devices
          pulseaudio --start
          pactl load-module module-null-sink sink_name=virtual_speaker
          pactl load-module module-virtual-source source_name=virtual_mic

      - name: Install Python dependencies for audio captcha
        run: |
          python -m pip install --upgrade pip
          pip install \
            selenium==4.18.1 \
            undetected-chromedriver==3.5.4 \
            pandas==2.1.4 \
            beautifulsoup4==4.12.2 \
            requests==2.31.0 \
            lxml==4.9.3 \
            fake-useragent==1.4.0 \
            python-dateutil==2.8.2 \
            pydub==0.25.1 \
            SpeechRecognition==3.10.0 \
            ftplib==0.8.0
            python-doenv==1.0.0
      - name: Setup virtual display and audio environment
        run: |
          # Start Xvfb for headless display
          Xvfb :99 -screen 0 1920x1080x24 -ac +extension GLX +render -noreset &
          export DISPLAY=:99
          
          # Setup pulseaudio for virtual audio
          pulseaudio --start --exit-idle-time=-1
          pactl load-module module-null-sink sink_name=virtual_speaker
          pactl load-module module-virtual-source source_name=virtual_mic
          
          echo "‚úÖ Virtual display and audio environment ready"

      - name: Run Google Shopping Scraper with Audio Captcha
        env:
          DISPLAY: :99
          FTP_HOST: ${{ secrets.FTP_HOST }}
          FTP_USER: ${{ secrets.FTP_USER }}
          FTP_PASS: ${{ secrets.FTP_PASS }}
          FTP_PATH: ${{ secrets.FTP_PATH }}
          FTP_PORT: ${{ secrets.FTP_PORT || '21' }}
          PULSE_SERVER: localhost
          PULSE_SOURCE: virtual_mic
          PULSE_SINK: virtual_speaker
        run: |
          echo "üöÄ Starting Google Shopping Scraper with Audio Captcha Support"
          echo "=============================================================="
          echo "Chunk ID: ${{ matrix.chunk_id }} of ${{ github.event.inputs.total_chunks || 4 }}"
          echo "Input file: ${{ github.event.inputs.input_filename || 'google_shopping.csv' }}"
          echo "Audio captcha solving: ENABLED"
          echo "=============================================================="
          # Set environment variables for audio
          export DISPLAY=:99
          export PULSE_SERVER=localhost
          export PULSE_SOURCE=virtual_mic
          export PULSE_SINK=virtual_speaker
          
          # Create output directory
          mkdir -p output

          # Check results
          echo " ready script:"
          # Run the scraper
          python gshopping/gscrappercitest.py \
            --chunk-id ${{ matrix.chunk_id }} \
            --total-chunks ${{ github.event.inputs.total_chunks || 4 }} \
            --input-file "${{ github.event.inputs.input_filename || 'google_shopping.csv' }}"
          
          # Check results
          echo "üìä Results summary:"
          ls -la output/*.csv 2>/dev/null || echo "No CSV files generated"
          echo "=============================================================="

      - name: Upload chunk results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: chunk-${{ matrix.chunk_id }}
          path: output/
          retention-days: 1

      - name: Cleanup temporary audio files
        if: always()
        run: |
          echo "üßπ Cleaning up temporary audio files..."
          rm -f *.mp3 *.wav *.png 2>/dev/null || true
          echo "Cleanup complete!"

  merge:
    needs: scrape
    runs-on: ubuntu-latest
    if: always()

    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install pandas
        run: |
          python -m pip install --upgrade pip
          pip install pandas==2.1.4

      - name: Download all artifacts
        uses: actions/download-artifact@v4
        with:
          path: chunks
          pattern: chunk-*
          merge-multiple: true

      - name: Merge CSV files
        run: |
          echo "üîÑ Merging CSV files from all chunks..."
          
          # Create merge script
          cat > merge_results.py << 'EOF'
          import os
          import glob
          import pandas as pd
          from datetime import datetime
          
          def merge_csv_files(pattern, output_prefix):
              files = glob.glob(pattern)
              if not files:
                  print(f"‚ö†Ô∏è No files found for pattern: {pattern}")
                  return None
              
              print(f"Found {len(files)} files for {output_prefix}")
              
              # Read and merge all CSV files
              dfs = []
              for file in files:
                  try:
                      df = pd.read_csv(file)
                      dfs.append(df)
                      print(f"‚úì Read {len(df)} rows from {os.path.basename(file)}")
                  except Exception as e:
                      print(f"‚úó Error reading {file}: {e}")
              
              if not dfs:
                  print("‚ö†Ô∏è No data to merge")
                  return None
              
              # Merge all dataframes
              merged_df = pd.concat(dfs, ignore_index=True)
              
              # Generate timestamp
              timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
              output_file = f"{output_prefix}_{timestamp}.csv"
              
              # Save merged file
              merged_df.to_csv(output_file, index=False)
              print(f"‚úÖ Saved {len(merged_df)} rows to {output_file}")
              
              return output_file
          
          # Merge product files
          print("Merging product files...")
          product_files = merge_csv_files("chunks/**/*product*.csv", "merged_products")
          
          # Merge seller files  
          print("Merging seller files...")
          seller_files = merge_csv_files("chunks/**/*seller*.csv", "merged_sellers")
          
          # Check if any files were created
          if not product_files and not seller_files:
              print("‚ùå No CSV files were merged. Check if scraper generated any output.")
              exit(1)
          EOF
          
          python merge_results.py

      - name: Upload merged files to FTP
        env:
          FTP_HOST: ${{ secrets.FTP_HOST }}
          FTP_USER: ${{ secrets.FTP_USER }}
          FTP_PASS: ${{ secrets.FTP_PASS }}
          FTP_PATH: ${{ secrets.FTP_PATH }}
        run: |
          set -e
          echo "üì§ Uploading merged files to FTP..."
          
          # Install lftp if not present
          if ! command -v lftp &> /dev/null; then
              sudo apt-get update
              sudo apt-get install -y lftp
          fi
          
          upload_file() {
              local file="$1"
              if [ -f "$file" ]; then
                  echo "Uploading $file..."
                  
                  cat > /tmp/ftp_commands.lftp << EOF
set ftp:ssl-allow no
set net:timeout 30
set net:max-retries 3
set net:reconnect-interval-base 5
open $FTP_HOST
user $FTP_USER $FTP_PASS
mkdir -p $FTP_PATH
cd $FTP_PATH
put $file
bye
EOF
                  
                  lftp -f /tmp/ftp_commands.lftp
                  rm -f /tmp/ftp_commands.lftp
                  echo "‚úÖ Uploaded: $file"
              else
                  echo "‚ö†Ô∏è File not found: $file"
              fi
          }
          
          # Upload all merged files
          for file in merged_products_*.csv merged_sellers_*.csv; do
              upload_file "$file"
          done
          
          echo "üìä FTP upload complete"

      - name: Upload merged artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: merged-results
          path: |
            merged_products_*.csv
            merged_sellers_*.csv
          retention-days: 7

      - name: Create summary report
        run: |
          echo "## üìä Google Shopping Scraping Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # Count merged rows
          PRODUCT_ROWS=0
          SELLER_ROWS=0
          
          if ls merged_products_*.csv 1> /dev/null 2>&1; then
              PRODUCT_ROWS=$(tail -n +2 merged_products_*.csv 2>/dev/null | wc -l | tr -d ' ' || echo "0")
          fi
          
          if ls merged_sellers_*.csv 1> /dev/null 2>&1; then
              SELLER_ROWS=$(tail -n +2 merged_sellers_*.csv 2>/dev/null | wc -l | tr -d ' ' || echo "0")
          fi
          
          echo "### üìà Results" >> $GITHUB_STEP_SUMMARY
          echo "- **Total Products Scraped**: $PRODUCT_ROWS" >> $GITHUB_STEP_SUMMARY
          echo "- **Total Seller Entries**: $SELLER_ROWS" >> $GITHUB_STEP_SUMMARY
          echo "- **Input File**: ${{ github.event.inputs.input_filename || 'google_shopping.csv' }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Chunks Processed**: ${{ github.event.inputs.total_chunks || 4 }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Features**: Audio Captcha Solving, Headless Chrome, FTP Upload" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          if [ "$PRODUCT_ROWS" -gt 0 ]; then
              echo "### ‚úÖ Success" >> $GITHUB_STEP_SUMMARY
              echo "Scraping completed successfully with audio captcha support!" >> $GITHUB_STEP_SUMMARY
          else
              echo "### ‚ö†Ô∏è Warning" >> $GITHUB_STEP_SUMMARY
              echo "No products were scraped. Check if:" >> $GITHUB_STEP_SUMMARY
              echo "1. Input CSV file exists on FTP" >> $GITHUB_STEP_SUMMARY
              echo "2. FTP credentials are correct" >> $GITHUB_STEP_SUMMARY
              echo "3. Target site structure hasn't changed" >> $GITHUB_STEP_SUMMARY
          fi

  notify:
    needs: merge
    runs-on: ubuntu-latest
    if: always()

    steps:
      - name: Workflow Summary
        run: |
          echo "=========================================="
          echo "üèÅ Google Shopping Scraper Workflow Complete"
          echo "=========================================="
          echo "Repository: $GITHUB_REPOSITORY"
          echo "Run ID: $GITHUB_RUN_ID"
          echo "Run URL: https://github.com/$GITHUB_REPOSITORY/actions/runs/$GITHUB_RUN_ID"
          echo "Status: ${{ job.status }}"
          echo "=========================================="