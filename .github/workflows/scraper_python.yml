name: Parallel Sitemap Scraper

on:
  workflow_dispatch:
    inputs:
      url:
        required: true
        default: "https://www.afastores.com"
      total_sitemaps:
        default: "15"
      sitemaps_per_job:
        default: "1"

jobs:
  plan:
    runs-on: ubuntu-latest
    outputs:
      matrix: ${{ steps.set-matrix.outputs.matrix }}
    steps:
      - id: set-matrix
        run: |
          TOTAL=${{ github.event.inputs.total_sitemaps }}
          PER_JOB=${{ github.event.inputs.sitemaps_per_job }}
          JOBS=$(( (TOTAL + PER_JOB - 1) / PER_JOB ))
          MATRIX="["
          for ((i=0; i<JOBS; i++)); do
            OFFSET=$(( i * PER_JOB ))
            MATRIX+="{\"offset\":$OFFSET,\"limit\":$PER_JOB,\"url\":\"${{ github.event.inputs.url }}\"},"
          done
          MATRIX="${MATRIX%,}]"
          echo "matrix=$MATRIX" >> $GITHUB_OUTPUT

  scrape:
    needs: plan
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      max-parallel: 1  # IMPORTANT: Do not run parallel to avoid IP bans
      matrix:
        include: ${{ fromJson(needs.plan.outputs.matrix) }}
    steps:
      - uses: actions/checkout@v4
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.10"
      
      - name: Install dependencies
        run: |
          pip install curl_cffi beautifulsoup4
          
      - name: Run scraper
        env:
          CURR_URL: ${{ matrix.url }}
          SITEMAP_OFFSET: ${{ matrix.offset }}
          MAX_SITEMAPS: ${{ matrix.limit }}
          MAX_URLS_PER_SITEMAP: 100
        run: python scrapercloud.py

      - uses: actions/upload-artifact@v4
        with:
          name: chunk_${{ matrix.offset }}
          path: products_chunk_*.csv

  merge:
    needs: scrape
    runs-on: ubuntu-latest
    steps:
      - uses: actions/download-artifact@v4
        with:
          path: chunks
          pattern: chunk_*
          merge-multiple: true
      
      - name: Merge
        run: |
          head -n 1 $(ls chunks/*.csv | head -n 1) > final_output.csv
          for f in chunks/*.csv; do tail -n +2 "$f" >> final_output.csv; done
          
      - uses: actions/upload-artifact@v4
        with:
          name: final_csv
          path: final_output.csv